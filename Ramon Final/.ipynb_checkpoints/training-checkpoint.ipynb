{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time, copy\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_path = \"./data/combined/\"\n",
    "max_vals_path = \"./data/max_vals.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "max_vals = np.load(max_vals_path)\n",
    "print(max_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, mode, max_path=None, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "        train = []\n",
    "        test = []\n",
    "        \n",
    "        self.max_features = np.load(max_path)\n",
    "        \n",
    "        for filename in os.listdir(data_path):\n",
    "            index = int(filename[:-4])\n",
    "            if index % 10 == 0:\n",
    "                test.append(np.load(data_path+filename))\n",
    "            else:\n",
    "                train.append(np.load(data_path+filename))\n",
    "                \n",
    "        self.data = train if mode == \"train\" else test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        data = self.data[idx][1:].astype(np.float)\n",
    "        data = data / self.max_features\n",
    "        label = self.data[idx][0]\n",
    "        \n",
    "        if self.transform != None:\n",
    "            data = self.transform(label)\n",
    "        \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 1064, 'test': 118}\n"
     ]
    }
   ],
   "source": [
    "train_set = FeatureDataset(combined_path,\"train\",max_path=max_vals_path)\n",
    "train_loader = DataLoader(train_set, batch_size=16, num_workers=4, shuffle=True)\n",
    "\n",
    "test_set = FeatureDataset(combined_path,\"test\",max_path=max_vals_path)\n",
    "test_loader = DataLoader(test_set, batch_size=16, num_workers=4)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"test\": test_loader}\n",
    "dataset_sizes = {\"train\": len(train), \"test\": len(test_set)}\n",
    "\n",
    "print(dataset_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            model.train()\n",
    "    \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                inputs = inputs.float().squeeze()\n",
    "                labels = labels.float().squeeze()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs).squeeze()                   \n",
    "                    loss = criterion(outputs, labels)\n",
    "                    preds = torch.round(outputs)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "                \n",
    "            if phase == 'train' and scheduler != None:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=10, bias=False)\n",
      "  (1): Linear(in_features=10, out_features=1, bias=False)\n",
      "  (2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "my_model = nn.Sequential(nn.Linear(50,10,bias=False),nn.Linear(10,1,bias=False), nn.Sigmoid())\n",
    "criterion = nn.BCELoss()\n",
    "print(my_model)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.SGD(my_model.parameters(), lr=0.5)\n",
    "optimizer_ft = optim.Adam(my_model.parameters(),lr=0.05, weight_decay=0.0001)\n",
    "lr_scheduler = None\n",
    "# lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=25, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.0410 Acc: 0.6156\n",
      "test Loss: 0.0441 Acc: 0.4915\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.0407 Acc: 0.6259\n",
      "test Loss: 0.0596 Acc: 0.5932\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.0383 Acc: 0.6579\n",
      "test Loss: 0.0390 Acc: 0.6780\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.0366 Acc: 0.6842\n",
      "test Loss: 0.0385 Acc: 0.7119\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.0383 Acc: 0.6457\n",
      "test Loss: 0.0453 Acc: 0.6525\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.0365 Acc: 0.6682\n",
      "test Loss: 0.0383 Acc: 0.7119\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.0350 Acc: 0.6992\n",
      "test Loss: 0.0384 Acc: 0.6949\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.0364 Acc: 0.6748\n",
      "test Loss: 0.0444 Acc: 0.5932\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.0341 Acc: 0.7049\n",
      "test Loss: 0.0412 Acc: 0.7034\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.7124\n",
      "test Loss: 0.0363 Acc: 0.7203\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.0335 Acc: 0.7246\n",
      "test Loss: 0.0355 Acc: 0.7288\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.0355 Acc: 0.7002\n",
      "test Loss: 0.0387 Acc: 0.7203\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.0340 Acc: 0.7143\n",
      "test Loss: 0.0412 Acc: 0.6356\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.6945\n",
      "test Loss: 0.0369 Acc: 0.7203\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.6823\n",
      "test Loss: 0.0421 Acc: 0.6780\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.7237\n",
      "test Loss: 0.0359 Acc: 0.7288\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.0331 Acc: 0.7293\n",
      "test Loss: 0.0421 Acc: 0.6949\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.0318 Acc: 0.7397\n",
      "test Loss: 0.0346 Acc: 0.7542\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.7425\n",
      "test Loss: 0.0386 Acc: 0.6780\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.7453\n",
      "test Loss: 0.0516 Acc: 0.5847\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.7209\n",
      "test Loss: 0.0367 Acc: 0.7203\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.0339 Acc: 0.7105\n",
      "test Loss: 0.0407 Acc: 0.6780\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 0.7209\n",
      "test Loss: 0.0405 Acc: 0.6610\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.0336 Acc: 0.7265\n",
      "test Loss: 0.0371 Acc: 0.7542\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.0333 Acc: 0.7152\n",
      "test Loss: 0.0367 Acc: 0.7542\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.7312\n",
      "test Loss: 0.0356 Acc: 0.7712\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.7331\n",
      "test Loss: 0.0355 Acc: 0.7627\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.0332 Acc: 0.7105\n",
      "test Loss: 0.0815 Acc: 0.4915\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.0339 Acc: 0.7096\n",
      "test Loss: 0.0371 Acc: 0.7203\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.7378\n",
      "test Loss: 0.0485 Acc: 0.6695\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.0337 Acc: 0.7077\n",
      "test Loss: 0.0366 Acc: 0.7542\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.0308 Acc: 0.7603\n",
      "test Loss: 0.0351 Acc: 0.7627\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.0306 Acc: 0.7556\n",
      "test Loss: 0.0360 Acc: 0.8051\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.7321\n",
      "test Loss: 0.0396 Acc: 0.6780\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 0.7115\n",
      "test Loss: 0.0434 Acc: 0.6356\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.7387\n",
      "test Loss: 0.0378 Acc: 0.7458\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.7246\n",
      "test Loss: 0.0344 Acc: 0.7373\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.7227\n",
      "test Loss: 0.0356 Acc: 0.7542\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.7397\n",
      "test Loss: 0.0358 Acc: 0.7373\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.0334 Acc: 0.7180\n",
      "test Loss: 0.0359 Acc: 0.7627\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.7227\n",
      "test Loss: 0.0354 Acc: 0.7712\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.7293\n",
      "test Loss: 0.0385 Acc: 0.7373\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.0341 Acc: 0.7124\n",
      "test Loss: 0.0359 Acc: 0.7288\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.0337 Acc: 0.7237\n",
      "test Loss: 0.0373 Acc: 0.7373\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.0326 Acc: 0.7284\n",
      "test Loss: 0.0340 Acc: 0.7542\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.7481\n",
      "test Loss: 0.0341 Acc: 0.7458\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.7397\n",
      "test Loss: 0.0368 Acc: 0.7373\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.0316 Acc: 0.7519\n",
      "test Loss: 0.0353 Acc: 0.7373\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.7641\n",
      "test Loss: 0.0362 Acc: 0.7288\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.0326 Acc: 0.7397\n",
      "test Loss: 0.0342 Acc: 0.7627\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.0304 Acc: 0.7688\n",
      "test Loss: 0.0399 Acc: 0.7119\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.7434\n",
      "test Loss: 0.0336 Acc: 0.7542\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.0332 Acc: 0.7274\n",
      "test Loss: 0.0352 Acc: 0.7542\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.0314 Acc: 0.7378\n",
      "test Loss: 0.0406 Acc: 0.6864\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.7444\n",
      "test Loss: 0.0337 Acc: 0.7627\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.7622\n",
      "test Loss: 0.0516 Acc: 0.6780\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.0335 Acc: 0.7105\n",
      "test Loss: 0.0360 Acc: 0.7627\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.0307 Acc: 0.7509\n",
      "test Loss: 0.0347 Acc: 0.7627\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.7528\n",
      "test Loss: 0.0356 Acc: 0.7797\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.0314 Acc: 0.7491\n",
      "test Loss: 0.0384 Acc: 0.7034\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.7472\n",
      "test Loss: 0.0422 Acc: 0.6864\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.0321 Acc: 0.7331\n",
      "test Loss: 0.0638 Acc: 0.4915\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.7566\n",
      "test Loss: 0.0367 Acc: 0.7542\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.0308 Acc: 0.7406\n",
      "test Loss: 0.0370 Acc: 0.7542\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.7509\n",
      "test Loss: 0.0360 Acc: 0.7542\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.7509\n",
      "test Loss: 0.0406 Acc: 0.7034\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.0317 Acc: 0.7387\n",
      "test Loss: 0.0388 Acc: 0.7119\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.0344 Acc: 0.7115\n",
      "test Loss: 0.0350 Acc: 0.7542\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.7462\n",
      "test Loss: 0.0363 Acc: 0.7458\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.7547\n",
      "test Loss: 0.0347 Acc: 0.7542\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.0317 Acc: 0.7472\n",
      "test Loss: 0.0382 Acc: 0.7119\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.7199\n",
      "test Loss: 0.0369 Acc: 0.7542\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.0304 Acc: 0.7528\n",
      "test Loss: 0.0337 Acc: 0.7627\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.0331 Acc: 0.7359\n",
      "test Loss: 0.0336 Acc: 0.7542\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.7293\n",
      "test Loss: 0.0342 Acc: 0.7712\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.7528\n",
      "test Loss: 0.0341 Acc: 0.7542\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.0340 Acc: 0.6964\n",
      "test Loss: 0.0353 Acc: 0.7542\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.0314 Acc: 0.7397\n",
      "test Loss: 0.0345 Acc: 0.7542\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.0308 Acc: 0.7500\n",
      "test Loss: 0.0359 Acc: 0.7542\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.0314 Acc: 0.7547\n",
      "test Loss: 0.0346 Acc: 0.7542\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.0315 Acc: 0.7378\n",
      "test Loss: 0.0353 Acc: 0.7712\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.7444\n",
      "test Loss: 0.0354 Acc: 0.7373\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.7528\n",
      "test Loss: 0.0359 Acc: 0.7712\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.0298 Acc: 0.7585\n",
      "test Loss: 0.0370 Acc: 0.7542\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.0318 Acc: 0.7538\n",
      "test Loss: 0.0342 Acc: 0.7627\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.0323 Acc: 0.7406\n",
      "test Loss: 0.0344 Acc: 0.7458\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.0307 Acc: 0.7575\n",
      "test Loss: 0.0342 Acc: 0.7458\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.0315 Acc: 0.7293\n",
      "test Loss: 0.0376 Acc: 0.7119\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.0337 Acc: 0.7218\n",
      "test Loss: 0.0358 Acc: 0.7542\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.7660\n",
      "test Loss: 0.0339 Acc: 0.7966\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.7397\n",
      "test Loss: 0.0357 Acc: 0.7712\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.0296 Acc: 0.7660\n",
      "test Loss: 0.0377 Acc: 0.7458\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.7613\n",
      "test Loss: 0.0343 Acc: 0.7627\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.7491\n",
      "test Loss: 0.0435 Acc: 0.6356\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.7613\n",
      "test Loss: 0.0334 Acc: 0.7712\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.7444\n",
      "test Loss: 0.0346 Acc: 0.7627\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.0288 Acc: 0.7603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0340 Acc: 0.7627\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 0.7763\n",
      "test Loss: 0.0333 Acc: 0.7712\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.0294 Acc: 0.7820\n",
      "test Loss: 0.0340 Acc: 0.7458\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.7284\n",
      "test Loss: 0.0364 Acc: 0.7627\n",
      "\n",
      "Training complete in 0m 44s\n",
      "Best val Acc: 0.805085\n"
     ]
    }
   ],
   "source": [
    "final_model = train_model(my_model, \n",
    "                                                       criterion, \n",
    "                                                       optimizer_ft, \n",
    "                                                       lr_scheduler, \n",
    "                                                       dataloaders, \n",
    "                                                       dataset_sizes,\n",
    "                                                       num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_model.state_dict(), \"models/final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
